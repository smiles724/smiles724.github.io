	<div class="filter-container" style="margin-left: 2em;">
        <a href="#" class="filter-link active" id="filter-rl" onclick="showTopic('rl'); return false;">RLHF/RLVR</a>
        <span class="filter-separator">/</span>
        <a href="#" class="filter-link" id="filter-llm" onclick="showTopic('llm'); return false;">Language Models</a>
        <span class="filter-separator">/</span>
        <a href="#" class="filter-link" id="filter-agent" onclick="showTopic('agent'); return false;">Agentic System</a>
        <span class="filter-separator">/</span>
        <a href="#" class="filter-link" id="filter-bench" onclick="showTopic('bench'); return false;">Benchmark and Dataset</a>
        <span class="filter-separator">/</span>
<!--        <a href="#" class="filter-link" id="filter-agent" onclick="showTopic('agent'); return false;">Agents</a>-->
<!--        <span class="filter-separator">/</span>		-->
		<a href="#" class="filter-link" id="filter-vision" onclick="showTopic('vision'); return false;">Computer Vision</a>
    </div>

	<div id="section-rl" class="topic-section">
		<p style="margin-left: 4em;">
			<img src="img/paper/deepsearch.png" align="left" width="170" height="90"/>
			&nbsp&nbsp <b>DeepSearch: Overcome the Bottleneck of Reinforcement Learning with Verifiable Rewards via Monte Carlo Tree Search.</b>  <br>
			&nbsp&nbsp <b>Fang Wu*,</b> Weihao Xuan*, Heli Qi*, Ximing Lu, Aaron Tu, Li Erran Li, Yejin Choi<sup>&dagger;</sup><br>
			&nbsp&nbsp <span style="display: inline-block;background: #f7f7f7; color: #333333;padding: 2px 6px;border-radius: 3px;box-shadow: 0px 1px 2px rgba(0, 0, 0, 0.15); font-weight: normal;
    		font-size: 1.0em; font-family: 'Georgia', 'Times New Roman', serif;">Under Review</span> <br>
			&nbsp&nbsp <a href="">[Paper]</a>
			<br><br>
		</p>

		<p style="margin-left: 4em;">
			<img src="img/paper/mnpo.png" align="left" width="170" height="90"/>
			&nbsp&nbsp <b>Multiplayer Nash Preference Optimization.</b>
			<span style="margin-left: 6px; vertical-align: middle;"> <img src="https://img.shields.io/github/stars/smiles724/MNPO?style=social" alt="GitHub stars"/></span> <br>
			&nbsp&nbsp <b>Fang Wu*,</b> Xu Huang*, Weihao Xuan, Zhiwei Zhang, Yijia Xiao, Guancheng Wan, Xiaomin Li, Bing Hu, Peng Xia, Jure Leskovec, Yejin Choi<sup>&dagger;</sup><br>
			&nbsp&nbsp <span style="display: inline-block;background: #f7f7f7; color: #333333;padding: 2px 6px;border-radius: 3px;box-shadow: 0px 1px 2px rgba(0, 0, 0, 0.15); font-weight: normal;
    		font-size: 1.0em; font-family: 'Georgia', 'Times New Roman', serif;">Under Review</span> <br>
			&nbsp&nbsp <a href="">[Paper]</a>
			&nbsp&nbsp <a href="https://github.com/smiles724/MNPO">[Code]</a><br>
			<br>
		</p>

		<p style="margin-left: 4em;">
			<img src="img/paper/RLVR.png" align="left" width="170" height="90"/>
			&nbsp&nbsp <b>The Invisible Leash: Why RLVR May Not Escape Its Origin.</b>  <br>
			&nbsp&nbsp <b>Fang Wu*,</b> Weihao Xuan*, Ximing Lu, Zaid Harchaoui, Yejin Choi<sup>&dagger;</sup><br>
			&nbsp&nbsp <span style="display: inline-block;background: #f7f7f7; color: #333333;padding: 2px 6px;border-radius: 3px;box-shadow: 0px 1px 2px rgba(0, 0, 0, 0.15); font-weight: normal;
    		font-size: 1.0em; font-family: 'Georgia', 'Times New Roman', serif;">Under Review</span> <br>
			&nbsp&nbsp <a href="https://arxiv.org/abs/2507.14843">[Paper]</a>
			<br><br>
		</p>

		<p style="margin-left: 4em;">
			<img src="img/paper/trading.png" align="left" width="170" height="90"/>
			&nbsp&nbsp <b>Trading-R1: Financial Trading with LLM Reasoning via Reinforcement Learning.</b>
			<span style="margin-left: 6px; vertical-align: middle;"> <img src="https://img.shields.io/github/stars/TauricResearch/Trading-R1?style=social" alt="GitHub stars"/></span> <br>
			&nbsp&nbsp Yijia Xiao, Edward Sun, Tong Chen, <b>Fang Wu</b>, Di Luo, Wei Wang<sup>&dagger;</sup><br>
			&nbsp&nbsp <span style="display: inline-block;background: #f7f7f7; color: #333333;padding: 2px 6px;border-radius: 3px;box-shadow: 0px 1px 2px rgba(0, 0, 0, 0.15); font-weight: normal;
    		font-size: 1.0em; font-family: 'Georgia', 'Times New Roman', serif;">Under Review</span> <br>
			&nbsp&nbsp <a href="https://www.arxiv.org/abs/2509.11420">[Paper]</a>
			&nbsp&nbsp <a href="https://github.com/TauricResearch/Trading-R1">[Code]</a>
			<br>
		</p>
	</div>

	<div id="section-llm" class="topic-section hidden">
<!--	<h3 style="margin-left: 2em;">Large Language Models (LLMs)</h3>-->
		<p style="margin-left: 4em;">
			<img src="img/paper/relllm.png" align="left" width="170" height="90"/>
			&nbsp&nbsp <b>Large Language Models are Good Relational Learners.</b>
			<span style="margin-left: 6px; vertical-align: middle;"> <img src="https://img.shields.io/github/stars/smiles724/Rel-LLM?style=social" alt="GitHub stars"/></span> <br>
			&nbsp&nbsp <b>Fang Wu,</b> Vijay Prakash Dwivedi, Jure Leskovec<sup>&dagger;</sup><br>
			&nbsp&nbsp <span style="display: inline-block;background: #f7f7f7; color: #333333;padding: 2px 6px;border-radius: 3px;box-shadow: 0px 1px 2px rgba(0, 0, 0, 0.15); font-weight: normal;
    		font-size: 1.0em; font-family: 'Georgia', 'Times New Roman', serif;">ACL 2025</span> <br>
			&nbsp&nbsp <a href="https://arxiv.org/abs/2506.05725">[Paper]</a>
			&nbsp&nbsp <a href="https://github.com/smiles724/Rel-LLM">[Code]</a><br>
			<br>
		</p>
		<p style="margin-left: 4em;">
			<img src="img/paper/retrival_clinical.png" align="left" width="170" height="90"/>
			&nbsp&nbsp <b>Retrieval-Reasoning Large Language Model-based Synthetic Clinical Trial Generation</b>
			<span style="margin-left: 6px; vertical-align: middle;">
			  <img src="https://img.shields.io/github/stars/XuZR3x/Retrieval_Reasoning_Clinical_Trial_Generation?style=social" alt="GitHub stars"/>
			</span> <br>
			&nbsp&nbsp Zerui Xu, <b>Fang Wu,</b> Tianfan Fu, Yue Zhao<sup>&dagger;</sup><br>
			&nbsp&nbsp <span style="display: inline-block;background: #f7f7f7; color: #333333;padding: 2px 6px;border-radius: 3px;box-shadow: 0px 1px 2px rgba(0, 0, 0, 0.15); font-weight: normal;
    		font-size: 0.9em; font-family: 'Georgia', 'Times New Roman', serif;">ACM BCB 2025</span><br>
			&nbsp&nbsp <a href="https://arxiv.org/abs/2410.12476">[Paper]</a>
			&nbsp&nbsp <a href="https://github.com/XuZR3x/Retrieval_Reasoning_Clinical_Trial_Generation">[Code]</a> <br>
			<br>
		</p>
	</div>

	<div id="section-agent" class="topic-section hidden">
		<p style="margin-left: 4em;">
			<img src="img/paper/cellforge.png" align="left" width="170" height="90"/>
			&nbsp&nbsp <b>CellForge: Agentic Design of Virtual Cell Models</b>
			<span style="margin-left: 6px; vertical-align: middle;">
			  <img src="https://img.shields.io/github/stars/gersteinlab/CellForge?style=social" alt="GitHub stars"/>
			</span> <br>
			&nbsp&nbsp Xiangru Tang*, Zhuoyun Yu*, Jiapeng Chen*, Yan Cui, Daniel Shao, Weixu Wang, <b>Fang Wu</b>, Yuchen Zhuang, Wenqi Shi,
			Zhi Huang, Arman Cohan, Xihong Lin, Fabian Theis, Smita Krishnaswamy, Mark Gerstein<sup>&dagger;</sup><br>
			&nbsp&nbsp <span style="display: inline-block;background: #f7f7f7; color: #333333;padding: 2px 6px;border-radius: 3px;box-shadow: 0px 1px 2px rgba(0, 0, 0, 0.15); font-weight: normal;
    		font-size: 0.9em; font-family: 'Georgia', 'Times New Roman', serif;">Under Review</span><br>
			&nbsp&nbsp <a href="https://arxiv.org/abs/2508.02276">[Paper]</a>
			&nbsp&nbsp <a href="https://github.com/gersteinlab/CellForge">[Code]</a> <br>
			<br>
		</p>
		<p style="margin-left: 4em;">
			<img src="img/paper/debate.jpg" align="left" width="170" height="90"/>
			&nbsp&nbsp <b>When to Trust Context: Agentic Debates for Context Reliability</b>
			<span style="margin-left: 6px; vertical-align: middle;">
			  <img src="https://img.shields.io/github/stars/smiles724/Self-Reflective-Debates?style=social" alt="GitHub stars"/>
			</span> <br>
			&nbsp&nbsp Zeqi Zhou*, <b>Fang Wu</b>*<sup>&dagger;</sup>, Shayan Talaei*, Haokai Zhao, Cheng Meixin, Tinson Xu, Amin Saberi, Yejin Choi<br>
			&nbsp&nbsp <span style="display: inline-block;background: #f7f7f7; color: #333333;padding: 2px 6px;border-radius: 3px;box-shadow: 0px 1px 2px rgba(0, 0, 0, 0.15); font-weight: normal;
    		font-size: 0.9em; font-family: 'Georgia', 'Times New Roman', serif;">ACL 2025 KnowFM Workshop</span><br>
			&nbsp&nbsp <a href="https://arxiv.org/abs/2506.06020">[Paper]</a>
			&nbsp&nbsp <a href="https://github.com/smiles724/Self-Reflective-Debates">[Code]</a> <br>
			<br>
		</p>
		<p style="margin-left: 4em;">
			<img src="img/paper/locagent.png" align="left" width="170" height="90"/>
			&nbsp&nbsp <b>LocAgent: Graph-Guided LLM Agents for Code Localization.</b>
			<span style="margin-left: 6px; vertical-align: middle;">
			  <img src="https://img.shields.io/github/stars/gersteinlab/LocAgent?style=social" alt="GitHub stars"/>
			</span> <br>
			&nbsp&nbsp Zhaoling Chen*, Xiangru Tang*, Gangda Deng*, <b>Fang Wu,</b> Jialong Wu, Zhiwei Jiang, Viktor Prasanna, Arman Cohan, Xingyao Wang<sup>&dagger;</sup><br>
			&nbsp&nbsp <span style="display: inline-block;background: #f7f7f7; color: #333333;padding: 2px 6px;border-radius: 3px;box-shadow: 0px 1px 2px rgba(0, 0, 0, 0.15); font-weight: normal;
    		font-size: 0.9em; font-family: 'Georgia', 'Times New Roman', serif;">ACL 2025</span> <br>
			&nbsp&nbsp <a href="https://arxiv.org/abs/2503.09089">[Paper]</a>
			&nbsp&nbsp <a href="https://github.com/gersteinlab/LocAgent">[Code]</a><br>
			<br>
		</p>
		<p style="margin-left: 4em;">
			<img src="img/paper/agentkb.png" align="left" width="170" height="90"/>
			&nbsp&nbsp <b>Agent KB: Leveraging Cross-Domain Experience for Agentic Problem Solving.</b>
			<span style="margin-left: 6px; vertical-align: middle;">
			  <img src="https://img.shields.io/github/stars/OPPO-PersonalAI/Agent-KB?style=social" alt="GitHub stars"/>
			</span> <br>
			&nbsp&nbsp Xiangru Tang*, Tianrui Qin*, Tianhao Peng*, Ziyang Zhou, Daniel Shao, Tingting Du, Xinming Wei, Peng Xia, <b>Fang Wu,</b> He Zhu, Ge Zhang, Jiaheng Liu,
			Xingyao Wang, Sirui Hong, Chenglin Wu, Hao Cheng, Chi Wang, Wangchunshu Zhou<sup>&dagger;</sup><br>
			&nbsp&nbsp <span style="display: inline-block;background: #f7f7f7; color: #333333;padding: 2px 6px;border-radius: 3px;box-shadow: 0px 1px 2px rgba(0, 0, 0, 0.15); font-weight: normal;
    		font-size: 0.9em; font-family: 'Georgia', 'Times New Roman', serif;">Under Review</span> <br>
			&nbsp&nbsp <a href="https://arxiv.org/abs/2507.06229">[Paper]</a>
			&nbsp&nbsp <a href="https://github.com/OPPO-PersonalAI/Agent-KB">[Code]</a><br>
			<br>
		</p>

	</div>

	<div id="section-bench" class="topic-section hidden">
		<p style="margin-left: 4em;">
			<img src="img/paper/position_rlvr.png" align="left" width="170" height="90"/>
			&nbsp&nbsp <b>Position: The Hidden Costs and Measurement Gaps of Reinforcement Learning with Verifiable Rewards.</b>  <br>
			&nbsp&nbsp Aaron Tu*, Weihao Xuan*, Heli Qi*, Xu Huang, Qingcheng Zeng, Shayan Talaei, Yijia Xiao, Peng Xia, Xiangru Tang, Yuchen Zhuang, Bing Hu,
			Hanqun Cao, Wenqi Shi, Tianang Leng, Rui Yang, Yingjian Chen, Ziqi Wang, Irene Li, Nan Liu, Huaxiu Yao, Li Erran Li, Ge Liu, Amin Saberi,
			Naoto Yokoya, Jure Leskovec, Yejin Choi, <b>Fang Wu*,</b><sup>&dagger;</sup><br>
			&nbsp&nbsp <span style="display: inline-block;background: #f7f7f7; color: #333333;padding: 2px 6px;border-radius: 3px;box-shadow: 0px 1px 2px rgba(0, 0, 0, 0.15); font-weight: normal;
    		font-size: 1.0em; font-family: 'Georgia', 'Times New Roman', serif;">Under Review</span> <br>
			&nbsp&nbsp <a href="https://arxiv.org/pdf/2509.21882">[Paper]</a>
			<br><br>
		</p>

		<p style="margin-left: 4em;">
			<img src="img/paper/VeriGUI.png" align="left" width="170" height="90"/>
			&nbsp&nbsp <b>VeriGUI: Verifiable Long-Chain GUI Dataset</b>
			<span style="margin-left: 6px; vertical-align: middle;">
			  <img src="https://img.shields.io/github/stars/VeriGUI-Team/VeriGUI?style=social" alt="GitHub stars"/>
			</span> <br>
			&nbsp&nbsp Shunyu Liu, Minghao Liu, Huichi Zhou, Zhenyu Cui, Yang Zhou, Yuhao Zhou, Wendong Fan, Ge Zhang, Jiajun Shi, Weihao Xuan, Jiaxing Huang, Shuang Luo,
			<b>Fang Wu,</b> Heli Qi, Qingcheng Zeng, Ziqi Ren, Jialiang Gao, Jindi Lv, Junjie Wang, Aosong Feng, Heng Zhou, Wangchunshu Zhou, Zhenfei Yin, Wenlong Zhang, Guohao Li,
			Wenhao Yu, Irene Li, Lei Ma, Lei Bai, Qunshu Lin, Mingli Song, Dacheng Tao<sup>&dagger;</sup><br>
			&nbsp&nbsp <span style="display: inline-block;background: #f7f7f7; color: #333333;padding: 2px 6px;border-radius: 3px;box-shadow: 0px 1px 2px rgba(0, 0, 0, 0.15); font-weight: normal;
    		font-size: 0.9em; font-family: 'Georgia', 'Times New Roman', serif;">Under Review</span><br>
			&nbsp&nbsp <a href="https://arxiv.org/abs/2508.04026">[Paper]</a>
			&nbsp&nbsp <a href="https://github.com/VeriGUI-Team/VeriGUI">[Code]</a> <br>
			<br>
		</p>

		<p style="margin-left: 4em;">
			<img src="img/paper/medbench.png" align="left" width="170" height="90"/>
			&nbsp&nbsp <b>MedAgentsBench: Benchmarking Thinking Models and Agent Frameworks for Complex Medical Reasoning</b>
			<span style="margin-left: 6px; vertical-align: middle;">
			  <img src="https://img.shields.io/github/stars/gersteinlab/medagents-benchmark?style=social" alt="GitHub stars"/>
			</span> <br>
			&nbsp&nbsp Xiangru Tang*, Daniel Shao*, Jiwoong Sohn*, Jiapeng Chen, Jiayi Zhang, Jinyu Xiang, <b>Fang Wu,</b> Yilun Zhao, Chenglin Wu, Wenqi Shi,
			Arman Cohan, Mark Gerstein<sup>&dagger;</sup><br>
			&nbsp&nbsp <span style="display: inline-block;background: #f7f7f7; color: #333333;padding: 2px 6px;border-radius: 3px;box-shadow: 0px 1px 2px rgba(0, 0, 0, 0.15); font-weight: normal;
    		font-size: 0.9em; font-family: 'Georgia', 'Times New Roman', serif;">Under Review</span><br>
			&nbsp&nbsp <a href="https://arxiv.org/abs/2503.07459">[Paper]</a>
			&nbsp&nbsp <a href="https://github.com/gersteinlab/medagents-benchmark">[Code]</a> <br>
			<br>
		</p>
	</div>

	<div id="section-vision" class="topic-section hidden">
<!--	<h3 style="margin-left: 2em;">Computer Vision</h3>-->
		<p style="margin-left: 4em;">
			<img src="img/paper/semireward.png" align="left" width="170" height="90"/>
			  <b>&nbsp&nbsp SemiReward: A General Reward Model for Semi-supervised Learning</b>
			  <span style="margin-left: 6px; vertical-align: middle;">
				<img src="https://img.shields.io/github/stars/Westlake-AI/SemiReward?style=social" alt="GitHub stars"/>
			  </span><br>
			&nbsp&nbsp Siyuan Li*, Weiyang Jin*, Zedong Wang, <b>Fang Wu,</b>, Zicheng Liu, Cheng Tan, Stan Z. Li<sup>&dagger;</sup><br>
			&nbsp&nbsp <span style="display: inline-block;background: #f7f7f7; color: #333333;padding: 2px 6px;border-radius: 3px;box-shadow: 0px 1px 2px rgba(0, 0, 0, 0.15); font-weight: normal;
    		font-size: 0.9em; font-family: 'Georgia', 'Times New Roman', serif;">ICLR 2024</span> <br>
			&nbsp&nbsp <a href="https://openreview.net/pdf?id=dnqPvUjyRI">[Paper]</a>
			&nbsp&nbsp <a href="https://github.com/Westlake-AI/SemiReward">[Code]</a> <br>
			<br>
		</p>
		<p style="margin-left: 4em;">
			<img src="img/paper/mask.png" align="left" width="170" height="90"/>
			<b>&nbsp&nbsp Architecture-Agnostic Masked Image Modeling: From ViT back to CNN</b>
			<span style="margin-left: 6px; vertical-align: middle;">
				<img src="https://img.shields.io/github/stars/Westlake-AI/openmixup?style=social" alt="GitHub stars"/>
			</span><br>
			&nbsp&nbsp Siyuan Li*, Di Wu*, <b>Fang Wu,</b> Zelin Zang, Kai Wang, Lei Shang, Baigui Sun, Hao Li, Stan Z. Li<sup>&dagger;</sup><br>
			&nbsp&nbsp <span style="display: inline-block;background: #f7f7f7; color: #333333;padding: 2px 6px;border-radius: 3px;box-shadow: 0px 1px 2px rgba(0, 0, 0, 0.15); font-weight: normal;
    		font-size: 0.9em; font-family: 'Georgia', 'Times New Roman', serif;">ICML 2023</span> <br>
			&nbsp&nbsp <a href="https://proceedings.mlr.press/v202/li23af.html">[Paper]</a>
			&nbsp&nbsp <a href="https://github.com/Westlake-AI/openmixup">[Code]</a> <br>
			<br>
		</p>
	</div>
	<p></p>

